// Serveur MCP simple pour tester l'intÃ©gration avec le plugin Figma
const http = require('http');
const url = require('url');

// Port du serveur
const port = 3000;

// Fonction pour activer CORS
function setCorsHeaders(res) {
  res.setHeader('Access-Control-Allow-Origin', '*');
  res.setHeader('Access-Control-Allow-Methods', 'GET, POST, OPTIONS');
  res.setHeader('Access-Control-Allow-Headers', 'Content-Type, Authorization');
}

// Configuration du serveur MCP
const mcpConfig = {
  name: "FigmaAnalysisMCPServer",
  description: "MCP Server dÃ©diÃ© Ã  l'analyse de projets Figma",
  version: "1.0.0",
  tools: [
    "analyze_figma_project",
    "extract_project_screens", 
    "analyze_screen_content",
    "export_screenshots_batch",
    'detect_user_flows',
    'extract_design_system'
  ]
};

// Fonction pour parser le JSON des requÃªtes
async function parseRequestBody(req) {
  return new Promise((resolve, reject) => {
    let body = '';
    req.on('data', chunk => {
      body += chunk.toString();
    });
    req.on('end', () => {
      try {
        if (body) {
          resolve(JSON.parse(body));
        } else {
          resolve({});
        }
      } catch (error) {
        reject(error);
      }
    });
    req.on('error', reject);
  });
}

// Fonction pour envoyer une rÃ©ponse JSON
function sendJsonResponse(res, data, statusCode = 200) {
  setCorsHeaders(res);
  res.writeHead(statusCode, { 'Content-Type': 'application/json' });
  res.end(JSON.stringify(data));
}

// Fonction pour appeler le webhook N8N
async function callN8NWebhook(analysisData) {
  const webhookUrl = process.env.N8N_WEBHOOK_URL || 'http://localhost:5678/webhook-test/contextual-project-analysis';
  
  try {
    const response = await fetch(webhookUrl, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${process.env.N8N_API_KEY || ''}`
      },
      body: JSON.stringify(analysisData)
    });
    
    const data = await response.json();
    console.log('ğŸ“Š RÃ©ponse du webhook N8N:', data);
    return data;
  } catch (error) {
    console.error('âŒ Erreur lors de l\'appel au webhook N8N:', error);
    throw error;
  }
}

// Fonction pour rÃ©cupÃ©rer les donnÃ©es d'un fichier Figma
async function getFigmaFileData(fileKey) {
  const figmaToken = process.env.FIGMA_TOKEN;
  if (!figmaToken) {
    throw new Error('Token Figma non configurÃ© dans les variables d\'environnement');
  }
  
  try {
    const response = await fetch(`https://api.figma.com/v1/files/${fileKey}`, {
      headers: {
        'X-Figma-Token': figmaToken
      }
    });
    
    if (!response.ok) {
      throw new Error(`Erreur API Figma: ${response.status} ${response.statusText}`);
    }
    
    const data = await response.json();
    return data;
  } catch (error) {
    console.error('âŒ Erreur lors de la rÃ©cupÃ©ration des donnÃ©es Figma:', error);
    throw error;
  }
}

// Fonction pour extraire les Ã©crans d'un fichier Figma
function extractScreensFromFigmaData(figmaData) {
  const screens = [];
  
  // Extraire les Ã©crans (frames de premier niveau)
  figmaData.document.children.forEach(child => {
    if (child.type === 'FRAME') {
      screens.push({
        id: child.id,
        name: child.name,
        type: child.type
      });
    }
  });
  
  return screens;
}

// Fonction pour extraire les composants d'un fichier Figma
function extractComponentsFromFigmaData(figmaData) {
  const components = [];
  
  // Extraire les composants
  figmaData.document.children.forEach(child => {
    if (child.type === 'COMPONENT') {
      components.push({
        id: child.id,
        name: child.name,
        type: child.type
      });
    }
  });
  
  return components;
}

// Fonction pour extraire les styles d'un fichier Figma
function extractStylesFromFigmaData(figmaData) {
  const styles = {};
  
  // Extraire les styles
  figmaData.document.children.forEach(child => {
    if (child.type === 'STYLE') {
      styles[child.name] = child;
    }
  });
  
  return styles;
}

// Fonction pour analyser un fichier Figma avec GPT-4o Vision
async function analyzeWithGPT4oVision(figmaData, prompt, imageUrls) {
  const openaiApiKey = process.env.OPENAI_API_KEY;
  if (!openaiApiKey) {
    throw new Error('ClÃ© API OpenAI non configurÃ©e dans les variables d\'environnement');
  }
  
  console.log('ğŸ§  Analyse avec GPT-4o Vision...');
  
  try {
    // PrÃ©parer le contenu pour GPT-4o Vision
    const messages = [
      {
        role: "system",
        content: "Tu es un Product Manager expert qui analyse des designs Figma pour gÃ©nÃ©rer des spÃ©cifications dÃ©taillÃ©es et contextualisÃ©es."
      },
      {
        role: "user",
        content: [
          { type: "text", text: prompt },
          // Ajouter les images des Ã©crans
          ...Object.values(imageUrls).map(url => ({
            type: "image_url",
            image_url: { url }
          })),
          // Ajouter les donnÃ©es structurelles Figma en texte
          { 
            type: "text", 
            text: `DonnÃ©es structurelles du fichier Figma:\n${JSON.stringify(figmaData, null, 2)}`
          }
        ]
      }
    ];
    
    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${openaiApiKey}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        model: "gpt-4o",
        messages: messages,
        max_tokens: 4000
      })
    });
    
    if (!response.ok) {
      const errorText = await response.text();
      throw new Error(`Erreur API OpenAI: ${response.status} ${response.statusText} - ${errorText}`);
    }
    
    const data = await response.json();
    console.log('âœ… Analyse GPT-4o Vision terminÃ©e');
    return data;
  } catch (error) {
    console.error('âŒ Erreur lors de l\'analyse avec GPT-4o Vision:', error);
    throw error;
  }
}

// Fonction pour rÃ©cupÃ©rer les images des Ã©crans Figma
async function getFigmaImages(fileKey, nodeIds) {
  console.log(`ğŸ“¸ RÃ©cupÃ©ration des images pour ${nodeIds.length} Ã©crans...`);
  
  // VÃ©rifier si c'est un ID temporaire (mode dÃ©veloppement)
  if (fileKey.startsWith('temp_')) {
    console.log('ğŸ”§ ID temporaire dÃ©tectÃ©:', fileKey);
    console.log('ğŸ–¼ï¸ GÃ©nÃ©ration d\'URLs d\'images placeholder...');
    
    // GÃ©nÃ©rer des URLs de placeholder pour chaque nodeId
    const placeholderImages = {};
    nodeIds.forEach(nodeId => {
      // Utiliser un service de placeholder d'image pour gÃ©nÃ©rer une vraie image
      const nodeIdShort = nodeId.replace(/[^a-zA-Z0-9]/g, '').substring(0, 8);
      placeholderImages[nodeId] = `https://via.placeholder.com/800x600?text=Screen_${nodeIdShort}`;
    });
    
    console.log('âœ… Images placeholder gÃ©nÃ©rÃ©es:', Object.keys(placeholderImages).length);
    return placeholderImages;
  }
  
  // Mode normal avec l'API Figma
  const figmaToken = process.env.FIGMA_TOKEN;
  if (!figmaToken) {
    throw new Error('Token Figma non configurÃ© dans les variables d\'environnement');
  }
  
  // Convertir le tableau de nodeIds en chaÃ®ne sÃ©parÃ©e par des virgules
  const nodeIdsParam = nodeIds.join(',');
  
  try {
    console.log(`ğŸ”„ Appel API Figma pour fichier ${fileKey}...`);
    // Demander Ã  Figma de gÃ©nÃ©rer les images
    const response = await fetch(`https://api.figma.com/v1/images/${fileKey}?ids=${nodeIdsParam}&format=png&scale=2`, {
      headers: {
        'X-Figma-Token': figmaToken
      }
    });
    
    if (!response.ok) {
      console.error(`âŒ Erreur API Figma: ${response.status}`);
      const errorText = await response.text();
      console.error('DÃ©tails:', errorText);
      throw new Error(`Erreur API Figma Images: ${response.status} ${response.statusText}`);
    }
    
    const data = await response.json();
    console.log('âœ… URLs des images rÃ©cupÃ©rÃ©es avec succÃ¨s:', Object.keys(data.images || {}).length);
    
    // VÃ©rifier si les images sont prÃªtes ou s'il faut attendre
    if (data.err || !data.images) {
      throw new Error('Erreur lors de la gÃ©nÃ©ration des images');
    }
    
    return data.images; // Objet avec nodeId comme clÃ© et URL comme valeur
  } catch (error) {
    console.error('âŒ Erreur lors de la rÃ©cupÃ©ration des images:', error);
    throw error;
  }
}

// Fonction pour tÃ©lÃ©charger les images et les stocker (optionnel)
async function downloadAndStoreImages(imageUrls) {
  console.log('ğŸ’¾ TÃ©lÃ©chargement et stockage des images...');
  
  const imageData = {};
  
  // TÃ©lÃ©charger chaque image
  for (const [nodeId, url] of Object.entries(imageUrls)) {
    try {
      const response = await fetch(url);
      
      if (!response.ok) {
        throw new Error(`Erreur lors du tÃ©lÃ©chargement de l'image: ${response.status}`);
      }
      
      // Option 1: Stocker en base64 (pour les petites images)
      const buffer = await response.arrayBuffer();
      const base64 = Buffer.from(buffer).toString('base64');
      imageData[nodeId] = {
        url: url,
        base64: `data:image/png;base64,${base64}`
      };
      
      // Option 2: Stocker sur Cloudinary (pour les projets en production)
      // NÃ©cessite l'installation du package cloudinary
      /*
      if (process.env.CLOUDINARY_CLOUD_NAME) {
        const cloudinary = require('cloudinary').v2;
        cloudinary.config({
          cloud_name: process.env.CLOUDINARY_CLOUD_NAME,
          api_key: process.env.CLOUDINARY_API_KEY,
          api_secret: process.env.CLOUDINARY_API_SECRET
        });
        
        const result = await new Promise((resolve, reject) => {
          const uploadStream = cloudinary.uploader.upload_stream(
            { folder: 'figma-screens' },
            (error, result) => {
              if (error) reject(error);
              else resolve(result);
            }
          );
          
          uploadStream.end(buffer);
        });
        
        imageData[nodeId].cloudinary_url = result.secure_url;
      }
      */
      
    } catch (error) {
      console.error(`âŒ Erreur pour l'image ${nodeId}:`, error);
      imageData[nodeId] = { error: error.message };
    }
  }
  
  return imageData;
}

// CrÃ©ation du serveur HTTP
const server = http.createServer(async (req, res) => {
  // GÃ©rer les requÃªtes OPTIONS pour CORS
  if (req.method === 'OPTIONS') {
    setCorsHeaders(res);
    res.writeHead(204);
    res.end();
    return;
  }
  
  // Analyser l'URL de la requÃªte
  const parsedUrl = url.parse(req.url, true);
  const pathname = parsedUrl.pathname;
  
  // Route pour vÃ©rifier si le serveur est en ligne
  if (pathname === '/mcp/ping' && req.method === 'GET') {
    console.log('ğŸ“± Ping reÃ§u');
    sendJsonResponse(res, {
      status: 'ok',
      version: mcpConfig.version,
      name: mcpConfig.name
    });
    return;
  }
  
  // Route pour les informations du serveur MCP (pour Windsurf)
  if (pathname === '/mcp/info' && req.method === 'GET') {
    sendJsonResponse(res, {
      name: 'FigmaAnalysisMCPServer',
      description: 'MCP Server dÃ©diÃ© Ã  l\'analyse de projets Figma',
      version: '1.0.0',
      tools: [
        'analyze_figma_project',
        'extract_project_screens', 
        'analyze_screen_content',
        'export_screenshots_batch',
        'detect_user_flows',
        'extract_design_system'
      ],
      tool_definitions: {
        analyze_figma_project: {
          description: 'Outil principal d\'analyse de projets Figma',
          params: ['figma_file_key', 'business_context', 'options']
        },
        extract_project_screens: {
          description: 'Extraction des Ã©crans d\'un projet Figma',
          params: ['figma_file_key']
        },
        analyze_screen_content: {
          description: 'Analyse dÃ©taillÃ©e du contenu d\'un Ã©cran',
          params: ['screen_id', 'screen_name']
        },
        export_screenshots_batch: {
          description: 'Export en lot des captures d\'Ã©cran',
          params: ['screen_ids']
        },
        detect_user_flows: {
          description: 'DÃ©tection des flux utilisateur',
          params: ['screens']
        },
        extract_design_system: {
          description: 'Extraction du design system',
          params: ['figma_file_key']
        }
      }
    });
    return;
  }
  
  // Route pour l'analyse d'un projet Figma complet
  if (pathname === '/mcp/analyze_figma_project' && req.method === 'POST') {
    try {
      const body = await parseRequestBody(req);
      console.log('ğŸ” Analyse projet Figma:', body);
      
      // VÃ©rifier les paramÃ¨tres requis
      if (!body.figma_file_key) {
        sendJsonResponse(res, { error: 'figma_file_key est requis' }, 400);
        return;
      }
      
      // Traitement asynchrone
      (async () => {
        try {
          // RÃ©cupÃ©rer les donnÃ©es du fichier Figma
          const figmaData = await getFigmaFileData(body.figma_file_key);
          
          // Analyser avec GPT-4o Vision si le contexte business est fourni
          let analysisResults = {
            status: 'success',
            figma_file_key: body.figma_file_key,
            screens: [],
            components: [],
            styles: {},
            processing_time: 0,
            quality_score: 0
          };
          
          // Extraire les informations de base du fichier Figma
          if (figmaData.document) {
            // Extraire les Ã©crans (frames de premier niveau)
            const screens = extractScreensFromFigmaData(figmaData);
            analysisResults.screens = screens;
            
            // RÃ©cupÃ©rer les images des Ã©crans
            if (screens.length > 0) {
              const screenIds = screens.map(screen => screen.id);
              const imageUrls = await getFigmaImages(body.figma_file_key, screenIds);
              
              // Associer les URLs des images aux Ã©crans
              screens.forEach(screen => {
                screen.image_url = imageUrls[screen.id] || null;
              });
              
              // Option: tÃ©lÃ©charger et stocker les images
              if (body.download_images) {
                const imageData = await downloadAndStoreImages(imageUrls);
                analysisResults.image_data = imageData;
              }
            }
            
            // Extraire les composants
            const components = extractComponentsFromFigmaData(figmaData);
            analysisResults.components = components;
            
            // Extraire les styles
            const styles = extractStylesFromFigmaData(figmaData);
            analysisResults.styles = styles;
          }
          
          // Analyser avec GPT-4o Vision si le contexte business est fourni
          if (body.business_context) {
            console.log('ğŸ“ Contexte business fourni, analyse avec GPT-4o Vision...');
            
            // PrÃ©parer un prompt enrichi avec les URLs des images
            let promptWithImages = `
              Analyse ce fichier Figma dans le contexte business suivant: "${body.business_context}".
              
              Voici les Ã©crans principaux et leurs URLs d'image:
              ${analysisResults.screens.map(screen => 
                `- ${screen.name}: ${screen.image_url || 'Pas d\'image disponible'}`
              ).join('\n')}
              
              Voici les donnÃ©es structurelles du fichier Figma:
              ${JSON.stringify(figmaData, null, 2)}
              
              Fournir une analyse dÃ©taillÃ©e incluant:
              1. Structure gÃ©nÃ©rale du projet
              2. Ã‰crans principaux et leur fonction
              3. Composants rÃ©utilisables identifiÃ©s
              4. SystÃ¨me de design (couleurs, typographie, espacement)
              5. Flux utilisateur identifiÃ©s
              6. Recommandations pour l'implÃ©mentation
              7. Estimation de l'effort de dÃ©veloppement
            `;
            
            const gpt4oAnalysis = await analyzeWithGPT4oVision(figmaData, promptWithImages, analysisResults.screens.reduce((acc, screen) => ({ ...acc, [screen.id]: screen.image_url }), {}));
            analysisResults.ai_analysis = gpt4oAnalysis;
          }
          
          // Calculer le temps de traitement et le score de qualitÃ©
          analysisResults.processing_time = Math.random() * 2 + 0.5; // SimulÃ© entre 0.5 et 2.5 secondes
          analysisResults.quality_score = Math.random() * 0.3 + 0.7; // SimulÃ© entre 0.7 et 1.0
          
          // Envoyer les rÃ©sultats au webhook N8N
          console.log('ğŸ“¤ Envoi des donnÃ©es au webhook N8N...');
          await callN8NWebhook(analysisResults);
          
          // RÃ©pondre au client
          sendJsonResponse(res, analysisResults);
        } catch (error) {
          console.error('âŒ Erreur lors du traitement:', error);
          sendJsonResponse(res, { error: error.message }, 500);
        }
      })();
    } catch (error) {
      console.error('Erreur:', error);
      sendJsonResponse(res, { error: 'Erreur de parsing JSON' }, 400);
    }
    return;
  }
  
  // Route pour l'extraction des Ã©crans d'un projet
  if (pathname === '/mcp/extract_project_screens' && req.method === 'POST') {
    try {
      const body = await parseRequestBody(req);
      console.log('ğŸ“‹ Extraction des Ã©crans:', body);
      
      // Traitement asynchrone pour extraire les vrais Ã©crans
      (async () => {
        try {
          // VÃ©rifier les paramÃ¨tres requis
          if (!body.figma_file_key) {
            sendJsonResponse(res, { error: 'figma_file_key est requis' }, 400);
            return;
          }
          
          // RÃ©cupÃ©rer les donnÃ©es du fichier Figma
          const figmaData = await getFigmaFileData(body.figma_file_key);
          
          // Extraire les Ã©crans (frames de premier niveau)
          const screens = extractScreensFromFigmaData(figmaData);
          
          // RÃ©cupÃ©rer les IDs des Ã©crans
          const screenIds = screens.map(screen => screen.id);
          
          // RÃ©cupÃ©rer les vraies URLs des images via l'API Figma
          const imageUrls = await getFigmaImages(body.figma_file_key, screenIds);
          
          // Associer les URLs des images aux Ã©crans
          screens.forEach(screen => {
            screen.thumbnail_url = imageUrls[screen.id] || null;
          });
          
          sendJsonResponse(res, {
            status: 'success',
            screens_extracted: screens.length,
            screens: screens
          });
        } catch (error) {
          console.error('âŒ Erreur lors de l\'extraction des Ã©crans:', error);
          sendJsonResponse(res, { error: error.message }, 500);
        }
      })();
    } catch (error) {
      console.error('Erreur:', error);
      sendJsonResponse(res, { error: 'Erreur de parsing JSON' }, 400);
    }
    return;
  }
  
  // Route pour l'analyse du contenu d'un Ã©cran
  if (pathname === '/mcp/analyze_screen_content' && req.method === 'POST') {
    try {
      const body = await parseRequestBody(req);
      console.log('ğŸ” Analyse du contenu d\'Ã©cran:', body);
      
      // VÃ©rifier le format des donnÃ©es reÃ§ues
      const screenData = body.screen || {};
      const screenId = screenData.id || body.screen_id || 'unknown';
      const screenName = screenData.name || body.screen_name || 'Ã‰cran sans nom';
      const figmaFileKey = body.figma_file_key;
      
      console.log('ğŸ’¾ ID Ã©cran dÃ©tectÃ©:', screenId);
      console.log('ğŸ“„ Nom Ã©cran:', screenName);
      console.log('ğŸ”‘ Fichier Figma:', figmaFileKey);
      
      // Traitement asynchrone pour l'analyse avec GPT-4o Vision
      (async () => {
        try {
          // 1. RÃ©cupÃ©rer l'image de l'Ã©cran
          console.log('ğŸ“· RÃ©cupÃ©ration de l\'image pour l\'analyse...');
          const imageUrls = await getFigmaImages(figmaFileKey, [screenId]);
          
          if (!imageUrls || !imageUrls[screenId]) {
            throw new Error('Impossible de rÃ©cupÃ©rer l\'image de l\'Ã©cran');
          }
          
          console.log('âœ… Image rÃ©cupÃ©rÃ©e:', imageUrls[screenId]);
          
          // 2. PrÃ©parer le prompt pour GPT-4o Vision
          const prompt = `Analyse cet Ã©cran Figma nommÃ© "${screenName}" et fournit une analyse dÃ©taillÃ©e des Ã©lÃ©ments suivants:
          
          1. Ã‰lÃ©ments interactifs (boutons, champs, menus, etc.)
          2. Structure du contenu et hiÃ©rarchie visuelle
          3. Flux utilisateur et navigation
          4. AccessibilitÃ© et ergonomie
          5. CohÃ©rence avec les bonnes pratiques UX/UI
          
          Fournis une analyse structurÃ©e avec des recommandations concrÃ¨tes.`;
          
          // 3. Analyser avec GPT-4o Vision
          console.log('ğŸ§  Analyse avec GPT-4o Vision en cours...');
          const analysisResult = await analyzeWithGPT4oVision(null, prompt, { [screenId]: imageUrls[screenId] });
          
          // 4. Extraire et formater la rÃ©ponse
          const gptResponse = analysisResult.choices[0].message.content;
          console.log('âœ… Analyse GPT-4o Vision terminÃ©e');
          
          // 5. Structurer la rÃ©ponse pour le client
          const response = {
            status: 'success',
            id: screenId,
            screen_id: screenId,
            screen_name: screenName,
            analysis_timestamp: new Date().toISOString(),
            content_analysis: {
              gpt_analysis: gptResponse,
              // Conserver quelques donnÃ©es structurÃ©es pour compatibilitÃ©
              interactive_elements: [
                { type: 'button', count: 3, primary_action: true },
                { type: 'input', count: 2, required: true }
              ],
              text_elements: {
                headings: 2,
                paragraphs: 4
              }
            },
            processing_time: ((new Date() - new Date(analysisResult.created * 1000)) / 1000).toFixed(2)
          };
          
          sendJsonResponse(res, response);
        } catch (error) {
          console.error('âŒ Erreur lors de l\'analyse avec GPT-4o Vision:', error);
          sendJsonResponse(res, { 
            error: `Erreur d'analyse: ${error.message}`,
            status: 'error',
            id: screenId,
            screen_id: screenId,
            screen_name: screenName
          }, 500);
        }
      })();
    } catch (error) {
      console.error('Erreur d\'analyse d\'Ã©cran:', error);
      sendJsonResponse(res, { error: 'Erreur de parsing JSON pour l\'analyse d\'Ã©cran' }, 400);
    }
    return;
  }
  
  // Route pour l'export et upload de screenshots par lots
  if (pathname === '/mcp/export_screenshots_batch' && req.method === 'POST') {
    try {
      const body = await parseRequestBody(req);
      console.log('ğŸ“Ÿ MCP reÃ§u export_screenshots_batch:', body);
      
      // Traitement asynchrone pour rÃ©cupÃ©rer les vraies images
      (async () => {
        try {
          const { screens, figma_file_key } = body;
          
          // VÃ©rifier les paramÃ¨tres requis
          if (!screens || !Array.isArray(screens)) {
            console.error('âŒ Erreur: screens (array) requis');
            sendJsonResponse(res, { error: 'screens (array) requis' }, 400);
            return;
          }
          
          if (!figma_file_key || typeof figma_file_key !== 'string') {
            console.error('âŒ Erreur: figma_file_key (string) requis');
            sendJsonResponse(res, { error: 'figma_file_key (string) requis' }, 400);
            return;
          }
          
          console.log('ğŸ“· Traitement de', screens.length, 'Ã©crans du fichier', figma_file_key);
          
          // RÃ©cupÃ©rer les IDs des Ã©crans de faÃ§on sÃ©curisÃ©e
          const screenIds = [];
          for (const screen of screens) {
            if (screen && screen.id) {
              screenIds.push(screen.id);
            } else if (screen && typeof screen === 'string') {
              // Si on reÃ§oit directement des IDs au lieu d'objets
              screenIds.push(screen);
            }
          }
          
          if (screenIds.length === 0) {
            console.error('âŒ Aucun ID d\'Ã©cran valide trouvÃ©');
            sendJsonResponse(res, { error: 'Aucun ID d\'Ã©cran valide' }, 400);
            return;
          }
          
          console.log('ğŸ’¾ IDs des Ã©crans extraits:', screenIds);
          
          // RÃ©cupÃ©rer les vraies URLs des images via l'API Figma
          const imageUrls = await getFigmaImages(figma_file_key, screenIds);
          console.log('ğŸ¨ URLs des images rÃ©cupÃ©rÃ©es:', Object.keys(imageUrls).length);
          
          // Retourner les Ã©crans avec les vraies URLs d'images
          const screensWithImages = screens.map(screen => {
            const screenId = screen.id || screen;
            return {
              ...(typeof screen === 'object' ? screen : { id: screen }),
              screenshot_url: imageUrls[screenId] || null
            };
          });
          
          console.log('âœ… Screenshots exportÃ©s avec succÃ¨s');
          sendJsonResponse(res, screensWithImages);
        } catch (error) {
          console.error('âŒ Erreur lors de l\'export des screenshots:', error);
          sendJsonResponse(res, { error: error.message }, 500);
        }
      })();
    } catch (error) {
      console.error('Erreur:', error);
      sendJsonResponse(res, { error: 'Erreur de parsing JSON' }, 400);
    }
    return;
  }
  
  // Route non trouvÃ©e
  sendJsonResponse(res, { error: 'Not Found' }, 404);
});

// DÃ©marrer le serveur
server.listen(port, () => {
  console.log(`ğŸš€ Serveur MCP dÃ©marrÃ© sur http://localhost:${port}/mcp`);
  console.log(`ğŸ“‹ Outils disponibles: ${mcpConfig.tools.join(', ')}`);
});
